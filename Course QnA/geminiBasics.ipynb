{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9a4e00e-3679-4a81-8930-ea3b976d89e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import os\n",
    "\n",
    "\n",
    "api_key_path = r\"C:\\Users\\gupta\\GeminiApikey.txt\" \n",
    "\n",
    "\n",
    "with open(api_key_path, \"r\") as file:\n",
    "    api_key = file.read().strip() \n",
    "\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
    "\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\",temperature = 0.8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973040ca-eedf-4b9d-b1ee-74709c480be1",
   "metadata": {},
   "source": [
    " ## Load the CSV file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdbeb4b3-85b9-4b65-a131-daa395bcfcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "loader = CSVLoader(file_path='codebasics_faqs.csv', source_column=\"prompt\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77dabc93-7ce2-402a-9917-646e60eb7860",
   "metadata": {},
   "source": [
    "## Hugging Face Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "806ad75b-948d-4dc0-ab24-a737d04ba556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting InstructorEmbedding\n",
      "  Downloading InstructorEmbedding-1.0.1-py2.py3-none-any.whl.metadata (20 kB)\n",
      "Downloading InstructorEmbedding-1.0.1-py2.py3-none-any.whl (19 kB)\n",
      "Installing collected packages: InstructorEmbedding\n",
      "Successfully installed InstructorEmbedding-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install InstructorEmbedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4397bea8-d772-470a-b9d4-cf54e8dea221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: InstructorEmbedding in c:\\users\\gupta\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\gupta\\anaconda3\\lib\\site-packages (4.0.1)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-4.0.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.50.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.11.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.30.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
      "Downloading sentence_transformers-4.0.2-py3-none-any.whl (340 kB)\n",
      "   ---------------------------------------- 0.0/340.6 kB ? eta -:--:--\n",
      "   ------- -------------------------------- 61.4/340.6 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 340.6/340.6 kB 5.3 MB/s eta 0:00:00\n",
      "Installing collected packages: sentence-transformers\n",
      "  Attempting uninstall: sentence-transformers\n",
      "    Found existing installation: sentence-transformers 4.0.1\n",
      "    Uninstalling sentence-transformers-4.0.1:\n",
      "      Successfully uninstalled sentence-transformers-4.0.1\n",
      "Successfully installed sentence-transformers-4.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade InstructorEmbedding sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db349b2f-5b54-4df2-b4c4-de8ed55ea53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: InstructorEmbedding==1.0.1 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Collecting sentence-transformers==2.2.2\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "     ---------------------------------------- 0.0/86.0 kB ? eta -:--:--\n",
      "     ------------- ------------------------ 30.7/86.0 kB 660.6 kB/s eta 0:00:01\n",
      "     -------------------------------------- 86.0/86.0 kB 970.7 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from sentence-transformers==2.2.2) (4.50.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from sentence-transformers==2.2.2) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from sentence-transformers==2.2.2) (2.6.0)\n",
      "Collecting torchvision (from sentence-transformers==2.2.2)\n",
      "  Downloading torchvision-0.21.0-cp311-cp311-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from sentence-transformers==2.2.2) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from sentence-transformers==2.2.2) (1.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from sentence-transformers==2.2.2) (1.11.4)\n",
      "Requirement already satisfied: nltk in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from sentence-transformers==2.2.2) (3.8.1)\n",
      "Collecting sentencepiece (from sentence-transformers==2.2.2)\n",
      "  Downloading sentencepiece-0.2.0-cp311-cp311-win_amd64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from sentence-transformers==2.2.2) (0.30.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1.3)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.6.0->sentence-transformers==2.2.2) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers==2.2.2) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2) (0.5.3)\n",
      "Requirement already satisfied: click in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers==2.2.2) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers==2.2.2) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers==2.2.2) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from torchvision->sentence-transformers==2.2.2) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2) (2025.1.31)\n",
      "Downloading sentencepiece-0.2.0-cp311-cp311-win_amd64.whl (991 kB)\n",
      "   ---------------------------------------- 0.0/991.5 kB ? eta -:--:--\n",
      "   --------------------- ----------------- 542.7/991.5 kB 17.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 716.8/991.5 kB 9.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 901.1/991.5 kB 7.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  983.0/991.5 kB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 991.5/991.5 kB 5.2 MB/s eta 0:00:00\n",
      "Downloading torchvision-0.21.0-cp311-cp311-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.5/1.6 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 0.6/1.6 MB 6.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.8/1.6 MB 5.7 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.8/1.6 MB 5.7 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.8/1.6 MB 5.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.3/1.6 MB 4.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.5/1.6 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 4.5 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py): started\n",
      "  Building wheel for sentence-transformers (setup.py): finished with status 'done'\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125953 sha256=b068d6cac186589870e031b77af35b50f2b0e30b510d4001cb4bef946fcae467\n",
      "  Stored in directory: c:\\users\\gupta\\appdata\\local\\pip\\cache\\wheels\\ff\\27\\bf\\ffba8b318b02d7f691a57084ee154e26ed24d012b0c7805881\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: sentencepiece, torchvision, sentence-transformers\n",
      "  Attempting uninstall: sentence-transformers\n",
      "    Found existing installation: sentence-transformers 4.0.2\n",
      "    Uninstalling sentence-transformers-4.0.2:\n",
      "      Successfully uninstalled sentence-transformers-4.0.2\n",
      "Successfully installed sentence-transformers-2.2.2 sentencepiece-0.2.0 torchvision-0.21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-huggingface 0.1.2 requires sentence-transformers>=2.6.0, but you have sentence-transformers 2.2.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install InstructorEmbedding==1.0.1 sentence-transformers==2.2.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfc68344-a634-404e-a148-372326136719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting huggingface_hub==0.14.1\n",
      "  Downloading huggingface_hub-0.14.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from huggingface_hub==0.14.1) (3.13.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from huggingface_hub==0.14.1) (2023.10.0)\n",
      "Requirement already satisfied: requests in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from huggingface_hub==0.14.1) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from huggingface_hub==0.14.1) (4.65.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from huggingface_hub==0.14.1) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from huggingface_hub==0.14.1) (4.12.2)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from huggingface_hub==0.14.1) (24.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub==0.14.1) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from requests->huggingface_hub==0.14.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from requests->huggingface_hub==0.14.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from requests->huggingface_hub==0.14.1) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from requests->huggingface_hub==0.14.1) (2025.1.31)\n",
      "Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
      "   ---------------------------------------- 0.0/224.5 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/224.5 kB ? eta -:--:--\n",
      "   -------------------------------------- - 215.0/224.5 kB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 224.5/224.5 kB 3.5 MB/s eta 0:00:00\n",
      "Installing collected packages: huggingface_hub\n",
      "  Attempting uninstall: huggingface_hub\n",
      "    Found existing installation: huggingface-hub 0.30.1\n",
      "    Uninstalling huggingface-hub-0.30.1:\n",
      "      Successfully uninstalled huggingface-hub-0.30.1\n",
      "Successfully installed huggingface_hub-0.14.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-huggingface 0.1.2 requires huggingface-hub>=0.23.0, but you have huggingface-hub 0.14.1 which is incompatible.\n",
      "langchain-huggingface 0.1.2 requires sentence-transformers>=2.6.0, but you have sentence-transformers 2.2.2 which is incompatible.\n",
      "tokenizers 0.21.1 requires huggingface-hub<1.0,>=0.16.4, but you have huggingface-hub 0.14.1 which is incompatible.\n",
      "transformers 4.50.3 requires huggingface-hub<1.0,>=0.26.0, but you have huggingface-hub 0.14.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub==0.14.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e894386a-bc04-4f17-959a-9af42050f0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: InstructorEmbedding==1.0.1 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: sentence-transformers==2.2.2 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Collecting transformers==4.30.2\n",
      "  Downloading transformers-4.30.2-py3-none-any.whl.metadata (113 kB)\n",
      "     ---------------------------------------- 0.0/113.6 kB ? eta -:--:--\n",
      "     ---------- -------------------------- 30.7/113.6 kB 640.0 kB/s eta 0:00:01\n",
      "     -------------------------------------- 113.6/113.6 kB 1.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: huggingface_hub==0.14.1 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (0.14.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from sentence-transformers==2.2.2) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from sentence-transformers==2.2.2) (2.6.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from sentence-transformers==2.2.2) (0.21.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from sentence-transformers==2.2.2) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from sentence-transformers==2.2.2) (1.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from sentence-transformers==2.2.2) (1.11.4)\n",
      "Requirement already satisfied: nltk in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from sentence-transformers==2.2.2) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from sentence-transformers==2.2.2) (0.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from transformers==4.30.2) (3.13.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from transformers==4.30.2) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from transformers==4.30.2) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from transformers==4.30.2) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from transformers==4.30.2) (2.31.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.30.2)\n",
      "  Downloading tokenizers-0.13.3-cp311-cp311-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from transformers==4.30.2) (0.5.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from huggingface_hub==0.14.1) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from huggingface_hub==0.14.1) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (3.1.3)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers==2.2.2) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch>=1.6.0->sentence-transformers==2.2.2) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers==2.2.2) (0.4.6)\n",
      "Requirement already satisfied: click in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers==2.2.2) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers==2.2.2) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from requests->transformers==4.30.2) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from requests->transformers==4.30.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from requests->transformers==4.30.2) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from requests->transformers==4.30.2) (2025.1.31)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers==2.2.2) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from torchvision->sentence-transformers==2.2.2) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\gupta\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers==2.2.2) (2.1.3)\n",
      "Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
      "   ---------------------------------------- 0.0/7.2 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.6/7.2 MB 11.8 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 0.8/7.2 MB 8.0 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.9/7.2 MB 6.5 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.9/7.2 MB 6.6 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.9/7.2 MB 6.6 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 1.5/7.2 MB 5.2 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 1.6/7.2 MB 5.2 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 1.8/7.2 MB 5.0 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.0/7.2 MB 4.8 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.0/7.2 MB 4.8 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.0/7.2 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.2/7.2 MB 4.0 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 2.5/7.2 MB 4.3 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 2.7/7.2 MB 4.2 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 2.9/7.2 MB 4.2 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 3.1/7.2 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 3.3/7.2 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 3.5/7.2 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 3.6/7.2 MB 4.1 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 3.8/7.2 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 4.0/7.2 MB 4.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 4.2/7.2 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 4.4/7.2 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 4.5/7.2 MB 4.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 4.7/7.2 MB 4.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 4.9/7.2 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 5.1/7.2 MB 4.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 5.3/7.2 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 5.4/7.2 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.6/7.2 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 5.8/7.2 MB 4.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 6.0/7.2 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 6.2/7.2 MB 4.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 6.3/7.2 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 6.5/7.2 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 6.7/7.2 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.9/7.2 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.1/7.2 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.2/7.2 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.2/7.2 MB 3.9 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.13.3-cp311-cp311-win_amd64.whl (3.5 MB)\n",
      "   ---------------------------------------- 0.0/3.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.4/3.5 MB 7.6 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 0.5/3.5 MB 5.7 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 0.7/3.5 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.9/3.5 MB 5.2 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 1.1/3.5 MB 4.9 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 1.3/3.5 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 1.5/3.5 MB 4.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.6/3.5 MB 4.5 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.8/3.5 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 2.0/3.5 MB 4.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 2.2/3.5 MB 4.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 2.3/3.5 MB 4.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 2.5/3.5 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 2.7/3.5 MB 4.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 2.9/3.5 MB 4.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 3.1/3.5 MB 4.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 3.2/3.5 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.4/3.5 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.5/3.5 MB 4.0 MB/s eta 0:00:00\n",
      "Installing collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.21.1\n",
      "    Uninstalling tokenizers-0.21.1:\n",
      "      Successfully uninstalled tokenizers-0.21.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.50.3\n",
      "    Uninstalling transformers-4.50.3:\n",
      "      Successfully uninstalled transformers-4.50.3\n",
      "Successfully installed tokenizers-0.13.3 transformers-4.30.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-huggingface 0.1.2 requires huggingface-hub>=0.23.0, but you have huggingface-hub 0.14.1 which is incompatible.\n",
      "langchain-huggingface 0.1.2 requires sentence-transformers>=2.6.0, but you have sentence-transformers 2.2.2 which is incompatible.\n",
      "langchain-huggingface 0.1.2 requires tokenizers>=0.19.1, but you have tokenizers 0.13.3 which is incompatible.\n",
      "langchain-huggingface 0.1.2 requires transformers>=4.39.0, but you have transformers 4.30.2 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install InstructorEmbedding==1.0.1 \\\n",
    "             sentence-transformers==2.2.2 \\\n",
    "             transformers==4.30.2 \\\n",
    "             huggingface_hub==0.14.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87be1e22-b7da-4db8-943a-9d8bb93377a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a09d3f77f245099b59c56b3819d94f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49d7dcc10a1342e79f5b89531e3a632f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be405faffea54115bce1e0f1d913725e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc7004726d04bb6a8cc81b21687b35a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6461117a6a24762a628bb09acf50754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e090a30f1efa4099a5a335a78ac31721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/2.41k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "514fa363d17b4ea69f9c993c03e7e303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading modules.json:   0%|          | 0.00/461 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "\n",
    "\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "instructor_embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-large\")\n",
    "\n",
    "e = instructor_embeddings.embed_query(\"What is your refund policy?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a36a8b4-5bea-454c-9e5b-a5dac11c1ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43dbcd7-735e-418c-8965-069a34511e22",
   "metadata": {},
   "source": [
    "## Vector store using FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "944a6c15-0ba5-4b12-9f89-8017713bea42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "vectordb = FAISS.from_documents(documents=docs,embedding=instructor_embeddings)\n",
    "\n",
    "retriever = vectordb.as_retriever(score_threshold = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c2729b9-82be-46dc-be1a-48ca232e9d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_8304\\3956196717.py:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  rdocs = retriever.get_relevant_documents(\"how about job placement support?\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(id='72be6e24-461c-46ca-afaf-aca9d1acde3f', metadata={'source': 'Do you provide any job assistance?', 'row': 11}, page_content='prompt: Do you provide any job assistance?\\nresponse: Yes, We help you with resume and interview preparation along with that we help you in building online credibility, and based on requirements we refer candidates to potential recruiters.'),\n",
       " Document(id='0a705e07-6cbb-4985-9f02-20854cfbb64a', metadata={'source': 'Will this course guarantee me a job?', 'row': 33}, page_content='prompt: Will this course guarantee me a job?\\nresponse: We created a much lighter version of this course on YouTube available for free (click this link) and many people gave us feedback that they were able to fetch jobs (see testimonials). Now this paid course is at least 5x better than the YouTube course which gives us ample confidence that you will be able to get a job. However, we want to be honest and do not want to make any impractical promises! Our guarantee is to prepare you for the job market by teaching the most relevant skills, knowledge & timeless principles good enough to fetch the job.'),\n",
       " Document(id='a2ae686a-55d3-4e42-8758-a63f3d261a39', metadata={'source': 'Will this bootcamp guarantee me a job?', 'row': 15}, page_content='prompt: Will this bootcamp guarantee me a job?\\nresponse: The courses included in this bootcamp are done by 9000+ learners and many of them have secured a job which gives us ample confidence that you will be able to get a job. However, we want to be honest and do not want to make any impractical promises! Our guarantee is to prepare you for the job market by teaching the most relevant skills, knowledge & timeless principles good enough to fetch the job.'),\n",
       " Document(id='d61ac088-1a8f-41a9-91e9-068324f6b38b', metadata={'source': 'Do you provide any virtual internship?', 'row': 14}, page_content='prompt: Do you provide any virtual internship?\\nresponse: Yes')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdocs = retriever.get_relevant_documents(\"how about job placement support?\")\n",
    "rdocs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ba0ccc-8108-4ec5-b387-aeec357ff042",
   "metadata": {},
   "source": [
    "# Create RetrievalQA chain along with prompt template 🚀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "671060a8-40b4-496e-9948-904dc13a1c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"Given the following context and a question, generate an answer based on this context only.\n",
    "In the answer try to provide as much text as possible from \"response\" section in the source document context without making much changes.\n",
    "If the answer is not found in the context, kindly state \"I don't know.\" Don't try to make up an answer.\n",
    "\n",
    "CONTEXT: {context}\n",
    "\n",
    "QUESTION: {question}\"\"\"\n",
    "\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(llm=llm,\n",
    "                            chain_type=\"stuff\",\n",
    "                            retriever=retriever,\n",
    "                            input_key=\"query\",\n",
    "                            return_source_documents=True,\n",
    "                            chain_type_kwargs=chain_type_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4034d128-98a2-4086-a311-377453ed30bd",
   "metadata": {},
   "source": [
    "\n",
    "# We are all set 👍🏼 Let's ask some questions now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "778fdfa3-3174-40aa-98c3-c7bd1a851578",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gupta\\AppData\\Local\\Temp\\ipykernel_8304\\1485025910.py:1: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chain(\"Do you guys provide internship and also do you offer EMI payments?\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'Do you guys provide internship and also do you offer EMI payments?',\n",
       " 'result': 'Yes\\n\\nNo',\n",
       " 'source_documents': [Document(id='d61ac088-1a8f-41a9-91e9-068324f6b38b', metadata={'source': 'Do you provide any virtual internship?', 'row': 14}, page_content='prompt: Do you provide any virtual internship?\\nresponse: Yes'),\n",
       "  Document(id='55b93a9a-6f4e-4290-aaf5-aa4ca684da87', metadata={'source': 'Do we have an EMI option?', 'row': 13}, page_content='prompt: Do we have an EMI option?\\nresponse: No'),\n",
       "  Document(id='72be6e24-461c-46ca-afaf-aca9d1acde3f', metadata={'source': 'Do you provide any job assistance?', 'row': 11}, page_content='prompt: Do you provide any job assistance?\\nresponse: Yes, We help you with resume and interview preparation along with that we help you in building online credibility, and based on requirements we refer candidates to potential recruiters.'),\n",
       "  Document(id='17165640-f667-4df4-9052-3603507c0a46', metadata={'source': 'How can I contact the instructors for any doubts/support?', 'row': 5}, page_content='prompt: How can I contact the instructors for any doubts/support?\\nresponse: We have created every lecture with a motive to explain everything in an easy-to-understand manner. While working on these lectures you could make mistakes in steps or have some doubts. You need to commit yourself to hold patience, make efforts & diagnose the errors yourself by googling in order to become truly job ready. For any questions, that Google cannot answer or if you hit a wall - we got you covered! You can join our active discord community. which is a dedicated platform to discuss & clear your doubts with fellow learners & mentors.')]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "chain(\"Do you guys provide internship and also do you offer EMI payments?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e76b66aa-e20b-44be-9ee9-701838ba9fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'do you have javascript course?',\n",
       " 'result': \"I don't know.\",\n",
       " 'source_documents': [Document(id='beadec60-64e0-479e-826f-955cee942c0a', metadata={'source': 'I have never done programming and belong to a non-technical background. Can I take this course?', 'row': 24}, page_content='prompt: I have never done programming and belong to a non-technical background. Can I take this course?\\nresponse: Yes, this is the perfect course for anyone who has never done coding and wants to build a career in the IT/Data Analytics industry or just wants to perform better in their current job or business using data.'),\n",
       "  Document(id='cdd4228e-bbfa-420d-a92d-8bd5535025e6', metadata={'source': 'I have never done programming in my life. Can I take this bootcamp?', 'row': 0}, page_content='prompt: I have never done programming in my life. Can I take this bootcamp?\\nresponse: Yes, this is the perfect bootcamp for anyone who has never done coding and wants to build a career in the IT/Data Analytics industry or just wants to perform better in your current job or business using data.'),\n",
       "  Document(id='f6933f66-aac8-49d2-b93e-d0f4ff32e66a', metadata={'source': 'Is there any prerequisite for taking this bootcamp ?', 'row': 2}, page_content='prompt: Is there any prerequisite for taking this bootcamp ?\\nresponse: Our bootcamp is specifically designed for beginners with no prior experience in this field. The only prerequisite is that you need to have a functional laptop with at least 4GB ram, an internet connection, and a thrill to learn data analysis.'),\n",
       "  Document(id='51993363-389a-4648-81a7-f0f226a74f86', metadata={'source': 'Is there any prerequisite for taking this course?', 'row': 35}, page_content='prompt: Is there any prerequisite for taking this course?\\nresponse: The only prerequisite is that you need to have a functional laptop with at least 4GB ram, internet connection and a thrill to learn data analysis.')]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain(\"do you have javascript course?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a6ce925-e266-40e4-a1e9-49c85a08a89a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'should I learn power bi or tableau?',\n",
       " 'result': 'This is a contextual question. If you are talking about a pure visualization tool Tableau is slightly better. Data connectors, modeling and transformation features are available in both. However, factually speaking Power BI is cheaper and offers tighter integration with the Microsoft environment. Since most companies use excel & Microsoft tools they start with Power BI or move towards Power BI for seamless integration with other Microsoft tools (called as Power platform). This makes the job openings grow at a much higher rate on Power BI and Power Platform. Also, Power BI has been leading the Gartner’s magic quadrant in BI for the last few years as the industry leader.',\n",
       " 'source_documents': [Document(id='0ea137a9-c45a-491c-b531-b811c49c5ba1', metadata={'source': '\\nPower BI or Tableau which one is better?', 'row': 29}, page_content='prompt: Power BI or Tableau which one is better?\\nresponse: This is a contextual question. If you are talking about a pure visualization tool Tableau is slightly better. Data connectors, modeling and transformation features are available in both. However, factually speaking Power BI is cheaper and offers tighter integration with the Microsoft environment. Since most companies use excel & Microsoft tools they start with Power BI or move towards Power BI for seamless integration with other Microsoft tools (called as Power platform). This makes the job openings grow at a much higher rate on Power BI and Power Platform. Also, Power BI has been leading the Gartner’s magic quadrant in BI for the last few years as the industry leader.'),\n",
       "  Document(id='ce384e6d-0120-4025-8a65-ae9d52b73d04', metadata={'source': 'What is different in this course from thousands of other Power BI courses available online?', 'row': 36}, page_content='prompt: What is different in this course from thousands of other Power BI courses available online?\\nresponse: Most of the courses available on the internet teach you how to build x & y without any business context and do not prepare you for the real business world. This course is rather an experience in which you will learn how to use Power BI & other non-technical skills to solve a real-life business problem using analytics. Here you focus on solving a business problem and in that process learn how Power BI can be used as a tool. This is how you will do the work when you start working as a data analyst/ Business analyst/ Power BI developer in the industry. This course will prepare you for not just fetching the job but, shine in it & grow further.'),\n",
       "  Document(id='bf960dbd-ff6a-46f0-9085-b25b9ffff978', metadata={'source': 'I already know basic Power BI, what benefit do I get by taking this course?', 'row': 37}, page_content='prompt: I already know basic Power BI, what benefit do I get by taking this course?\\nresponse: This course is taught through a true end-to-end project in a Consumer goods company involving all the steps mimicking the real business environment, so you will learn how to execute end-to-end projects Power BI projects successfully along with the business fundamentals. You will learn a lot of extra things such as Project management tools, effective communication techniques & organizational nuances.'),\n",
       "  Document(id='2cdec80d-6e8e-45f2-b7c4-d106e6e1bd1a', metadata={'source': 'Is this bootcamp enough for me in Microsoft Power BI and\\n Excel certifications?', 'row': 12}, page_content='prompt: Is this bootcamp enough for me in Microsoft Power BI and\\n Excel certifications?\\nresponse: Yes, this bootcamp will certainly help because we cover the majority of the skills measured in these exams. However, please be informed that this course focuses on Job ready aspects and not on all aspects required to clear the exams. In addition to this course, you might need to visit the official learning material designed by Microsoft which is available for free on their website.')]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain(\"should I learn power bi or tableau?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90551d3-22b6-4c2f-a185-b965da61e7b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
